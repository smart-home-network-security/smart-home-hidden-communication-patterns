{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define global variables and functions.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Global variables\n",
    "FIG_WIDTH           = 3.49\n",
    "LINE_THICKNESS      = 0.5\n",
    "GRID_LINE_THICKNESS = 0.25\n",
    "\n",
    "# Pandas settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Matplotlib settings\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Times New Roman',\n",
    "    'font.size': 9,\n",
    "    'axes.titlesize': 8,\n",
    "    'axes.labelsize': 8,\n",
    "    'xtick.labelsize': 7,\n",
    "    'ytick.labelsize': 7,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.titlesize': 12\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve event signature trees.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from enum import StrEnum\n",
    "import json\n",
    "\n",
    "\n",
    "class DeviceTypes(StrEnum):\n",
    "    \"\"\"\n",
    "    Enum class for the device types.\n",
    "    \"\"\"\n",
    "    PLUG   = \"plug\"\n",
    "    LIGHT  = \"light\"\n",
    "    CAMERA = \"camera\"\n",
    "\n",
    "\n",
    "class ExpCases(StrEnum):\n",
    "    \"\"\"\n",
    "    Enumerates the experimental cases,\n",
    "    i.e. the pairs device-app.\n",
    "    \"\"\"\n",
    "    ## Power plugs\n",
    "    # TP-Link HS110\n",
    "    TPLINK_PLUG = \"TpLinkPlug\"\n",
    "    TPLINK_PLUG_TAPO = \"TpLinkPlugTapo\"\n",
    "    TPLINK_PLUG_SMARTTHINGS = \"TpLinkPlugSmartThings\"\n",
    "    # SmartThings Outlet\n",
    "    SMARTTHINGS_OUTLET = \"SmartThingsOutlet\"\n",
    "    # Tapo P110\n",
    "    TAPO_PLUG = \"TapoPlug\"\n",
    "    TAPO_PLUG_SMARTTHINGS = \"TapoPlugSmartThings\"\n",
    "    # WOOX plug (Tuya)\n",
    "    TUYA_PLUG = \"TuyaPlug\"\n",
    "    ## Cameras\n",
    "    # Xiaomi\n",
    "    XIAOMI_CAMERA = \"XiaomiCamera\"\n",
    "    # Tapo C200\n",
    "    TAPO_CAMERA = \"TapoCamera\"\n",
    "    TAPO_CAMERA_SMARTTHINGS = \"TapoCameraSmartThings\"\n",
    "    # D-Link\n",
    "    DLINK_CAMERA = \"DLinkCamera\"\n",
    "    ## Light bulbs\n",
    "    # Philips Hue\n",
    "    HUE_LIGHT = \"HueLight\"\n",
    "    HUE_LIGHT_ESSENTIALS = \"HueLightEssentials\"\n",
    "    HUE_LIGHT_SMARTTHINGS = \"HueLightSmartThings\"\n",
    "    # Alecto (Tuya)\n",
    "    TUYA_LIGHT = \"TuyaLight\"\n",
    "    # Tapo L530E\n",
    "    TAPO_LIGHT = \"TapoLight\"\n",
    "    TAPO_LIGHT_SMARTTHINGS = \"TapoLightSmartThings\"\n",
    "\n",
    "\n",
    "class DictKeysMetrics(StrEnum):\n",
    "    \"\"\"\n",
    "    Enum class for the keys of the metrics dictionary.\n",
    "    \"\"\"\n",
    "    METRICS                   = \"metrics\"\n",
    "    FILE_TREE                 = \"file_tree\"\n",
    "    N_FIRST_LVL_NODES         = \"n_first_lvl_nodes\"\n",
    "    N_TOTAL_NODES             = \"n_total_nodes\"\n",
    "    MAX_DEPTH                 = \"max_depth\"\n",
    "    MAX_UNIQUE_DEPTH          = \"max_unique_depth\"\n",
    "    N_UNIQUE_NODES            = \"n_unique_nodes\"\n",
    "    NODE_DISCOVERY_DEPTH      = \"pdd\"\n",
    "    FIRST_LEVEL_NODE_COVERAGE = \"flnc\"\n",
    "    FIRST_LEVEL_NODE_LOSS     = \"flnl\"\n",
    "    ROBUSTNESS_SCORE          = \"robustness_score\"\n",
    "    DOMAIN_NAMES_LVL_1        = \"domain_names_lvl_1\"\n",
    "    DOMAIN_NAMES_HIDDEN       = \"domain_names_hidden\"\n",
    "    DNS_SERVERS_LVL_1         = \"dns_servers_lvl_1\"\n",
    "    DNS_SERVERS_HIDDEN        = \"dns_servers_hidden\"\n",
    "\n",
    "\n",
    "## Paths\n",
    "BASE_DIR = os.getcwd()\n",
    "DEVICES_DIR = os.path.join(BASE_DIR, \"devices\")\n",
    "\n",
    "list_trees = []\n",
    "for case in ExpCases:\n",
    "    case = case.value\n",
    "    paths_trees = glob.glob(os.path.join(DEVICES_DIR, \"*\", case, \"node_pruning\", \"*\", \"tree.json\"))\n",
    "    list_trees.extend(paths_trees)\n",
    "\n",
    "list_event_dirs = [Path(tree).parents[1] for tree in list_trees]\n",
    "fields_to_skip = [\"all_events\", \"full\", \"raw\", \"no_boot\", \"device\"]\n",
    "\n",
    "\n",
    "# Build mapping of device to event signature trees\n",
    "d = {}\n",
    "for event_dir in list_event_dirs:\n",
    "    event = os.path.basename(event_dir)\n",
    "    device_dir = os.path.dirname(event_dir)\n",
    "    device = os.path.basename(device_dir)\n",
    "    d[device] = {DictKeysMetrics.METRICS.name: {}}\n",
    "\n",
    "\n",
    "    ## Get list of event signature trees\n",
    "\n",
    "    # All events\n",
    "    list_json_file_tree_all_events = glob.glob(os.path.join(device_dir, \"tree.all_events.json\"))\n",
    "    for json_file_tree in list_json_file_tree_all_events:\n",
    "        d[device][DictKeysMetrics.METRICS.name][\"all_events\"] = {DictKeysMetrics.FILE_TREE.name: json_file_tree}\n",
    "\n",
    "    # Full device profile\n",
    "    list_json_file_tree_full = glob.glob(os.path.join(device_dir, \"node_pruning\", \"tree.device.json\"))\n",
    "    for json_file_tree in list_json_file_tree_full:\n",
    "        d[device][DictKeysMetrics.METRICS.name][\"device\"] = {DictKeysMetrics.FILE_TREE.name: json_file_tree}\n",
    "    \n",
    "    # Single events\n",
    "    list_json_file_tree_events = glob.glob(os.path.join(device_dir, \"node_pruning\", \"*\", \"tree.json\"))\n",
    "    for json_file_tree in list_json_file_tree_events:\n",
    "        event = Path(json_file_tree).parent.name\n",
    "        d[device][DictKeysMetrics.METRICS.name][event] = {DictKeysMetrics.FILE_TREE.name: json_file_tree}\n",
    "\n",
    "# Print tree JSON file paths\n",
    "print(f\"Number of unique events: {sum(1 for _, metrics in d.items() for _ in metrics[DictKeysMetrics.METRICS.name])}\")\n",
    "print(json.dumps(d, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add classifiers to the dictionary.\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "from enum import Enum\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "\n",
    "class DictKeysMetadata(Enum):\n",
    "    \"\"\"\n",
    "    Enum class for the classifier keys in the devices' dictionary.\n",
    "    \"\"\"\n",
    "    METADATA     = \"metadata\"\n",
    "    DEVICE_TYPE  = \"device-type\"\n",
    "    MANUFACTURER = \"manufacturer\"\n",
    "    APP          = \"app\"\n",
    "\n",
    "\n",
    "class Apps(Enum):\n",
    "    \"\"\"\n",
    "    Enum class for the covered companion apps.\n",
    "    \"\"\"\n",
    "    SMARTTHINGS = \"SmartThings\"\n",
    "    TUYA        = \"Tuya\"\n",
    "    OFFICIAL    = \"official\"\n",
    "    OTHER       = \"other\"\n",
    "\n",
    "\n",
    "for device in d:\n",
    "    with open(os.path.join(BASE_DIR, \"devices\", \"devices.yaml\"), \"r\") as f:\n",
    "        metadata_devices = yaml.safe_load(f)\n",
    "    \n",
    "    d[device][DictKeysMetadata.METADATA.name] = {\n",
    "        DictKeysMetadata.DEVICE_TYPE.name: metadata_devices[device][\"device-type\"],\n",
    "        DictKeysMetadata.MANUFACTURER.name: metadata_devices[device][\"manufacturer\"],\n",
    "        DictKeysMetadata.APP.name: metadata_devices[device].get(\"app\", Apps.OFFICIAL.value)\n",
    "    }\n",
    "    \n",
    "\n",
    "# Print devices' dictionary\n",
    "pprint(d)\n",
    "#print(json.dumps(d, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Domain names-related functions.\n",
    "\"\"\"\n",
    "\n",
    "from ipaddress import ip_address\n",
    "\n",
    "\n",
    "def is_domain_name(hostname: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the hostname is a domain name.\n",
    "\n",
    "    Args:\n",
    "        hostname (str): Hostname to check.\n",
    "    Returns:\n",
    "        bool: True if the hostname is a domain name, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ip_address(hostname)\n",
    "    except ValueError:\n",
    "        return \".\" in hostname\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_supported_field(protocol: str, field: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given protocol field could contain a domain name.\n",
    "\n",
    "    Args:\n",
    "        protocol (str): protocol\n",
    "        field (str): protocol field\n",
    "    Returns:\n",
    "        bool: True if the field is supported, False otherwise.\n",
    "    \"\"\"\n",
    "    supported_fields = [\n",
    "        (\"ipv4\", \"src\"), (\"ipv4\", \"dst\"),\n",
    "        (\"ipv6\", \"src\"), (\"ipv6\", \"dst\"),\n",
    "        (\"dns\", \"qname\")\n",
    "    ]\n",
    "    return (protocol, field) in supported_fields\n",
    "\n",
    "\n",
    "def get_domain_names(policy: dict) -> set[str]:\n",
    "    \"\"\"\n",
    "    Get the set of domain names a given policy accepts.\n",
    "\n",
    "    Args:\n",
    "        policy (dict): Policy to analyze.\n",
    "    Returns:\n",
    "        set[str]: Set of domain names.\n",
    "    \"\"\"\n",
    "    domain_names = set()\n",
    "\n",
    "    for protocol, fields in policy[\"protocols\"].items():\n",
    "        for field, value in fields.items():\n",
    "            if is_supported_field(protocol, field):\n",
    "                if not isinstance(value, list):\n",
    "                    value = [value]\n",
    "                for v in value:\n",
    "                    if is_domain_name(v):\n",
    "                        domain_names.add(v)\n",
    "\n",
    "    return domain_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DNS servers-related functions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def contains_dns_query(policy: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a given policy pertains to a DNS query.\n",
    "\n",
    "    Args:\n",
    "        policy (dict): Policy to analyze.\n",
    "    Returns:\n",
    "        bool: True if the policy pertains to a DNS query, False otherwise.\n",
    "    \"\"\"\n",
    "    # Check if the policy contains DNS protocol data\n",
    "    if \"dns\" not in policy[\"protocols\"]:\n",
    "        return False\n",
    "    \n",
    "    # Check if the policy is a DNS query\n",
    "    is_response = policy[\"protocols\"][\"dns\"].get(\"is_response\", False)\n",
    "    return not is_response\n",
    "\n",
    "\n",
    "def get_dns_servers(policy: dict) -> set[str]:\n",
    "    \"\"\"\n",
    "    Get the set of DNS servers a given policy is configured to use.\n",
    "\n",
    "    Args:\n",
    "        policy (dict): Policy to analyze.\n",
    "    Returns:\n",
    "        set[str]: set of DNS servers\n",
    "    \"\"\"\n",
    "    # If policy does not contain a DNS query, early return\n",
    "    if not contains_dns_query(policy):\n",
    "        return set()\n",
    "\n",
    "    # Policy contains a DNS query\n",
    "    protocol_data = policy[\"protocols\"]\n",
    "    dns_servers = set()\n",
    "    for ip_protocol in (\"ipv4\", \"ipv6\"):\n",
    "        dst = protocol_data.get(ip_protocol, {}).get(\"dst\", [])\n",
    "        if isinstance(dst, list):\n",
    "            dns_servers.update(dst)\n",
    "        else:\n",
    "            dns_servers.add(dst)\n",
    "\n",
    "    return dns_servers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute metrics over event signature trees.\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "from collections import deque\n",
    "from treelib import Tree\n",
    "from utils.tree import build_tree\n",
    "from utils.heuristic import get_node_flows, compare_policies\n",
    "\n",
    "\n",
    "def compute_metrics(tree: Tree, queue: deque, unique_policies: list, result: dict = {}) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively count the number of unique policies in the event signature tree.\n",
    "\n",
    "    Args:\n",
    "        tree (treelib.Tree): Complete event signature tree.\n",
    "        queue (deque): Queue of nodes to visit.\n",
    "        unique_policies (list): List of already counted unique policies.\n",
    "        result (dict): current computed metrics\n",
    "    Returns:\n",
    "        dict: Dictionary containing the computed metrics.\n",
    "    \"\"\"\n",
    "    # Get next node to visit\n",
    "    try:\n",
    "        depth, node_id = queue.popleft()\n",
    "    except IndexError:\n",
    "        # No node remaining, return result\n",
    "        return result\n",
    "    \n",
    "    # Skip root node\n",
    "    if node_id == \"0_root\":\n",
    "        # Add children to queue\n",
    "        for child in tree.children(node_id):\n",
    "            queue.append((depth + 1, child.identifier))\n",
    "        # Recursively visit children\n",
    "        return compute_metrics(tree, queue, unique_policies, result)\n",
    "    \n",
    "    ## Node is not the root, process it\n",
    "\n",
    "    # Get node (meta)data\n",
    "    node = tree.get_node(node_id)\n",
    "    if node is None:\n",
    "        return compute_metrics(tree, queue, unique_policies, result)\n",
    "    \n",
    "    # Get node policy\n",
    "    policies = get_node_flows(node)\n",
    "    policy = policies[-1]\n",
    "\n",
    "    # Check if node's policy is already present\n",
    "    is_policy_present = any(compare_policies(policy, p) for p in unique_policies)\n",
    "    if not is_policy_present:\n",
    "        ## New policy: add metrics\n",
    "        unique_policies.append(policy)\n",
    "\n",
    "        # Maximum tree depth of unique nodes\n",
    "        result[DictKeysMetrics.MAX_UNIQUE_DEPTH.name] = max(result.get(DictKeysMetrics.MAX_UNIQUE_DEPTH.name, 0), depth)\n",
    "\n",
    "        # Number of unique policies\n",
    "        result[DictKeysMetrics.N_UNIQUE_NODES.name] = result.get(DictKeysMetrics.N_UNIQUE_NODES.name, 0) + 1\n",
    "\n",
    "        # Robustness score\n",
    "        if depth == 1:\n",
    "            result[DictKeysMetrics.ROBUSTNESS_SCORE.name] = result.get(DictKeysMetrics.ROBUSTNESS_SCORE.name, 0)\n",
    "        elif depth > 1:\n",
    "            result[DictKeysMetrics.ROBUSTNESS_SCORE.name] = result.get(DictKeysMetrics.ROBUSTNESS_SCORE.name, 0) + 1\n",
    "\n",
    "        # Node discovery rate\n",
    "        if DictKeysMetrics.NODE_DISCOVERY_DEPTH.name not in result:\n",
    "            result[DictKeysMetrics.NODE_DISCOVERY_DEPTH.name] = {}\n",
    "        policy_discovery_depth = result[DictKeysMetrics.NODE_DISCOVERY_DEPTH.name]\n",
    "        policy_discovery_depth[depth] = policy_discovery_depth.get(depth, 0) + 1\n",
    "\n",
    "        # Domain names\n",
    "        domain_names = get_domain_names(policy)\n",
    "        if len(domain_names) > 0:\n",
    "            if depth == 1:\n",
    "                result[DictKeysMetrics.DOMAIN_NAMES_LVL_1.name]  = result.get(DictKeysMetrics.DOMAIN_NAMES_LVL_1.name, set()).union(domain_names)\n",
    "            elif depth > 1:\n",
    "                result[DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name] = result.get(DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name, set()).union(domain_names)\n",
    "        if DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name in result:\n",
    "            domain_names_lvl_1 = result.get(DictKeysMetrics.DOMAIN_NAMES_LVL_1.name, set())\n",
    "            result[DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name] = result[DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name].difference(domain_names_lvl_1)\n",
    "\n",
    "        # DNS resolvers\n",
    "        dns_servers = get_dns_servers(policy)\n",
    "        if len(dns_servers) > 0:\n",
    "            if depth == 1:\n",
    "                result[DictKeysMetrics.DNS_SERVERS_LVL_1.name]  = result.get(DictKeysMetrics.DNS_SERVERS_LVL_1.name, set()).union(dns_servers)\n",
    "            elif depth > 1:\n",
    "                result[DictKeysMetrics.DNS_SERVERS_HIDDEN.name] = result.get(DictKeysMetrics.DNS_SERVERS_HIDDEN.name, set()).union(dns_servers)\n",
    "        if DictKeysMetrics.DNS_SERVERS_HIDDEN.name in result:\n",
    "            dns_servers_lvl_1 = result.get(DictKeysMetrics.DNS_SERVERS_LVL_1.name, set())\n",
    "            result[DictKeysMetrics.DNS_SERVERS_HIDDEN.name] = result[DictKeysMetrics.DNS_SERVERS_HIDDEN.name].difference(dns_servers_lvl_1)\n",
    "\n",
    "        # Add children to queue\n",
    "        for child in tree.children(node_id):\n",
    "            queue.append((depth + 1, child.identifier))\n",
    "    \n",
    "    # Continue recursion\n",
    "    return compute_metrics(tree, queue, unique_policies, result)\n",
    "\n",
    "\n",
    "\n",
    "### COMPUTE METRICS ###\n",
    "\n",
    "for device in d:\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for _, metrics in metrics_device.items():\n",
    "        # Load event signature tree\n",
    "        tree_json_file = metrics[DictKeysMetrics.FILE_TREE.name]\n",
    "        with open(tree_json_file, \"r\") as f:\n",
    "            tree_json = json.load(f)\n",
    "        tree = build_tree(Tree(), tree_json)\n",
    "\n",
    "\n",
    "        ## Compute metrics\n",
    "\n",
    "        # Number of first level policies\n",
    "        first_level_nodes = tree.children(\"0_root\")\n",
    "        n_first_level_nodes = len(first_level_nodes)\n",
    "        metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name] = n_first_level_nodes\n",
    "\n",
    "        # Total number of policies\n",
    "        metrics[DictKeysMetrics.N_TOTAL_NODES.name] = tree.size() - 1  # Exclude root node\n",
    "\n",
    "        # Maximum tree depth\n",
    "        metrics[DictKeysMetrics.MAX_DEPTH.name] = tree.depth()\n",
    "\n",
    "        # Computed metrics\n",
    "        queue = deque([(0, \"0_root\")])\n",
    "        unique_policies = []\n",
    "        computed_metrics = compute_metrics(tree, queue, unique_policies, {})\n",
    "        metrics.update(computed_metrics)\n",
    "\n",
    "        # First-Level Node Coverage\n",
    "        n_unique_policies = metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "        flnc = n_first_level_nodes / n_unique_policies\n",
    "        metrics[DictKeysMetrics.FIRST_LEVEL_NODE_COVERAGE.name] = flnc\n",
    "\n",
    "        # First-Level Node Loss\n",
    "        flnl = (n_unique_policies - n_first_level_nodes) / n_unique_policies\n",
    "        metrics[DictKeysMetrics.FIRST_LEVEL_NODE_LOSS.name] = flnl\n",
    "\n",
    "\n",
    "pprint(d, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot count of discovered unique flow IDs.\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "# Initialize x & y vectors\n",
    "vectors = {\n",
    "    \"list_device_events\": [],\n",
    "    \"list_first_level_ids\": [],\n",
    "    \"list_hidden_ids\": [],\n",
    "}\n",
    "vectors_per_event = {\n",
    "    \"boot\": deepcopy(vectors),\n",
    "    \"others\": deepcopy(vectors)\n",
    "}\n",
    "\n",
    "# Retrieve data\n",
    "max_total_ids  = 0\n",
    "sum_hidden_ids = 0\n",
    "sum_total_ids  = 0\n",
    "for device in d:\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for event, metrics in metrics_device.items():\n",
    "        # Skip multiple events\n",
    "        if event in fields_to_skip:\n",
    "            continue\n",
    "\n",
    "        event_category = \"boot\" if event == \"boot\" else \"others\"\n",
    "        vectors_event = vectors_per_event[event_category]\n",
    "        vectors_event[\"list_device_events\"].append(f\"{device}-{event}\")\n",
    "        n_first_level_ids = metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name]\n",
    "        vectors_event[\"list_first_level_ids\"].append(n_first_level_ids)\n",
    "        n_hidden_ids = metrics[DictKeysMetrics.N_UNIQUE_NODES.name] - n_first_level_ids\n",
    "        vectors_event[\"list_hidden_ids\"].append(n_hidden_ids)\n",
    "\n",
    "        # Update aggregate values\n",
    "        max_total_ids = max(max_total_ids, metrics[DictKeysMetrics.N_UNIQUE_NODES.name])\n",
    "        sum_hidden_ids += n_hidden_ids\n",
    "        sum_total_ids += metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "\n",
    "print(f\"Sum of hidden flow IDs: {sum_hidden_ids}\")\n",
    "print(f\"Sum of total flow IDs: {sum_total_ids}\")\n",
    "print(f\"Percentage: {sum_hidden_ids / sum_total_ids * 100:.2f}%\")\n",
    "list_device_events = vectors_per_event[\"boot\"][\"list_device_events\"] + vectors_per_event[\"others\"][\"list_device_events\"]\n",
    "list_first_level_ids = vectors_per_event[\"boot\"][\"list_first_level_ids\"] + vectors_per_event[\"others\"][\"list_first_level_ids\"]\n",
    "list_hidden_ids = vectors_per_event[\"boot\"][\"list_hidden_ids\"] + vectors_per_event[\"others\"][\"list_hidden_ids\"]\n",
    "\n",
    "print(\"Device-event pairs:\")\n",
    "for i, device_event in enumerate(list_device_events, start=1):\n",
    "    print(f\"{device_event}: {i}\")\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (3.4, 1.7)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "# Plot stacked bars\n",
    "x = range(1, len(list_first_level_ids) + 1)\n",
    "ax.bar(x, list_first_level_ids, label=\"First-Level Flow IDs\", color='white', edgecolor='black', linewidth=LINE_THICKNESS)\n",
    "ax.bar(x, list_hidden_ids, bottom=list_first_level_ids, label=\"Hidden Flow IDs\", color='black', edgecolor='black', linewidth=LINE_THICKNESS)\n",
    "\n",
    "# Plot metadata\n",
    "ax.grid(axis=\"y\", linewidth=GRID_LINE_THICKNESS)\n",
    "#ax.set_xlabel(\"Event ID\")\n",
    "ax.set_ylabel(\"Count of Unique Flow IDs\")\n",
    "ax.legend()\n",
    "ax.set_xlim(0, len(list_first_level_ids) + 1)\n",
    "ax.set_xticks(range(1, len(list_first_level_ids) + 1))\n",
    "ax.set_xticklabels([i if i == 1 or i % 5 == 0 else \"\" for i in range(1, len(list_first_level_ids) + 1)])\n",
    "ax.set_yticks(range(0, max_total_ids + 1, 2))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure to paper repository\n",
    "#save_to_paper(fig, f\"count_flow-id.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Robustness Score for all device events.\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "# Initialize robustness score vector\n",
    "vectors = {\n",
    "    \"list_device_events\": [],\n",
    "    \"list_robustness\": []\n",
    "}\n",
    "vectors_per_event = {\n",
    "    \"boot\": deepcopy(vectors),\n",
    "    \"others\": deepcopy(vectors)\n",
    "}\n",
    "\n",
    "# Extract Robustness Score\n",
    "for device in d:\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for event, metrics in metrics_device.items():\n",
    "        # Skip multiple events\n",
    "        if event in fields_to_skip:\n",
    "            continue\n",
    "\n",
    "        event_category = \"boot\" if event == \"boot\" else \"others\"\n",
    "        vectors_event = vectors_per_event[event_category]\n",
    "        vectors_event[\"list_device_events\"].append(f\"{device}-{event}\")\n",
    "        vectors_event[\"list_robustness\"].append(metrics[DictKeysMetrics.ROBUSTNESS_SCORE.name])\n",
    "\n",
    "list_device_events = vectors_per_event[\"boot\"][\"list_device_events\"] + vectors_per_event[\"others\"][\"list_device_events\"]\n",
    "list_robustness = vectors_per_event[\"boot\"][\"list_robustness\"] + vectors_per_event[\"others\"][\"list_robustness\"]\n",
    "mean_robustness = np.mean(list_robustness)\n",
    "max_robustness  = max(list_robustness)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (3.4, 1.4)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "## Plot robustness score\n",
    "# Boot event\n",
    "vectors_boot = vectors_per_event[\"boot\"]\n",
    "x = range(1, len(vectors_boot[\"list_device_events\"]) + 1)\n",
    "ax.scatter(x, vectors_boot[\"list_robustness\"], label=\"Boot events\", color='black', marker='o', s=10)\n",
    "# Other events\n",
    "vectors_others = vectors_per_event[\"others\"]\n",
    "min_x = len(vectors_boot[\"list_device_events\"]) + 1\n",
    "x = range(min_x, min_x + len(vectors_others[\"list_device_events\"]))\n",
    "ax.scatter(x, vectors_others[\"list_robustness\"], label=\"Other events\", color='black', marker='x', s=15)\n",
    "\n",
    "# Plot mean\n",
    "print(f\"Mean Robustness Score: {mean_robustness}\")\n",
    "ax.axhline(mean_robustness, color='black', linestyle='--', label=f'Mean = {mean_robustness:.2f}', linewidth=1)\n",
    "\n",
    "# Plot metadata\n",
    "ax.grid(linewidth=GRID_LINE_THICKNESS)\n",
    "ax.set_xlim(0, len(list_device_events) + 1)\n",
    "ax.set_xticks(range(1, len(list_first_level_ids) + 1))\n",
    "ax.set_xticklabels([i if i == 1 or i % 5 == 0 else \"\" for i in range(1, len(list_device_events) + 1)])\n",
    "ax.set_yticks(range(0, max_robustness, 2))\n",
    "#ax.set_xlabel(\"Event ID\")\n",
    "ax.set_ylabel(\"Robustness Score\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure to paper repository\n",
    "#save_to_paper(fig, f\"robustness_score.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Robustness score as a stripplot.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "MEAN_LINE_WIDTH     = 0.5\n",
    "MEAN_LINE_THICKNESS = 2\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "classifiers = [DictKeysMetadata.DEVICE_TYPE, DictKeysMetadata.APP, DictKeysMetadata.MANUFACTURER]\n",
    "\n",
    "# Extract Robustness Score\n",
    "robustness = {}\n",
    "for device in d:\n",
    "    device_type = d[device][DictKeysMetadata.METADATA.name][DictKeysMetadata.DEVICE_TYPE.name]\n",
    "    app = d[device][DictKeysMetadata.METADATA.name][DictKeysMetadata.APP.name]\n",
    "    manufacturer = d[device][DictKeysMetadata.METADATA.name][DictKeysMetadata.MANUFACTURER.name]\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for event, metrics in metrics_device.items():\n",
    "        # Skip multiple events\n",
    "        if event in fields_to_skip:\n",
    "            continue\n",
    "\n",
    "        device_event = f\"{device}-{event}\"\n",
    "        robustness[device_event] = ((device_type, app, manufacturer), metrics[DictKeysMetrics.ROBUSTNESS_SCORE.name])\n",
    "\n",
    "# Sort by metadata\n",
    "list_robustness = []\n",
    "for i in range(3):\n",
    "    robustness_sorted = {k: v for k, v in sorted(robustness.items(), key=lambda item: sum(1 for metadata, _ in robustness.values() if metadata[i] == item[1][0][i]), reverse=True)}\n",
    "    list_robustness.append(robustness_sorted)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Initialize plot\n",
    "fig = plt.figure(figsize=(3.4,2))\n",
    "gs = GridSpec(1, 3, width_ratios=[1, 4/3, 2])\n",
    "gs.update(wspace=-1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.set_ylabel(\"Robustness Score\")\n",
    "ax2 = fig.add_subplot(gs[1], sharey=ax1)  # Share y-axis with ax1\n",
    "ax3 = fig.add_subplot(gs[2], sharey=ax1)  # Share y-axis with ax1\n",
    "axes = [ax1, ax2, ax3]\n",
    "\n",
    "for i, robustness in enumerate(list_robustness):\n",
    "\n",
    "    # Get x and y axes data\n",
    "    groups = list(dict.fromkeys([metadata[i] for metadata, _ in robustness.values()]))\n",
    "    for j, group in enumerate(groups, start=1):\n",
    "        y = [robustness for metadata, robustness in robustness.values() if metadata[i] == group]\n",
    "        x = [j] * len(y)\n",
    "\n",
    "        # Plot data\n",
    "        axes[i].scatter(x, y, alpha=0.6, color=\"black\", marker=\"x\")\n",
    "\n",
    "        if len(y) > 1:\n",
    "            # Add mean line\n",
    "            mean = np.mean(y)\n",
    "            x_start_mean = j - MEAN_LINE_WIDTH / 2\n",
    "            x_end_mean = j + MEAN_LINE_WIDTH / 2\n",
    "            axes[i].plot([x_start_mean, x_end_mean], [mean, mean], color='red', linewidth=MEAN_LINE_THICKNESS, label=\"Mean\" if j == 1 else None)\n",
    "        \n",
    "        # Add legend for mean on 3rd subplot\n",
    "        if i == 2:\n",
    "            axes[i].legend(handlelength=MEAN_LINE_WIDTH * 2, bbox_to_anchor=(0.6, 0.9))\n",
    "\n",
    "\n",
    "    # Replace categorical value \"SmartThings\" with \"ST\" for brevity\n",
    "    # try:\n",
    "    #     idx_st = groups.index(Apps.SMARTTHINGS.value)\n",
    "    #     groups[idx_st] = \"ST\"\n",
    "    # except ValueError:\n",
    "    #     pass\n",
    "\n",
    "    # Plot metadata\n",
    "    classifier = classifiers[i].name.lower()\n",
    "    axes[i].grid(axis='y')\n",
    "    axes[i].set_xticks(range(1, len(groups) + 1))\n",
    "    axes[i].set_xticklabels(groups, rotation=45, ha=\"right\")\n",
    "    max_robustness = max([value for _, value in robustness.values()])\n",
    "    axes[i].set_yticks(range(0, max_robustness + 1, 2))\n",
    "    xlabel = \"Device category\" if classifier == \"device_type\" else classifier.capitalize()\n",
    "    axes[i].set_xlabel(xlabel)\n",
    "    if i != 0:\n",
    "        plt.setp(axes[i].get_yticklabels(), visible=False)\n",
    "\n",
    "#fig.suptitle(\"Robustness Score\")\n",
    "plt.subplots_adjust(hspace=0)\n",
    "fig.align_xlabels(axes)\n",
    "gs.tight_layout(fig)\n",
    "plt.show()\n",
    "\n",
    "# Save figure to paper repository\n",
    "#save_to_paper(fig, \"robustness_grouped.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Domain names, first-level and hidden,\n",
    "for all device events.\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "# Initialize x & y vectors\n",
    "vectors = {\n",
    "    \"list_device_events\": [],\n",
    "    \"list_first_level_names\": [],\n",
    "    \"list_first_level_resolvers\": [],\n",
    "    \"list_hidden_names\": [],\n",
    "    \"list_hidden_resolvers\": []\n",
    "}\n",
    "vectors_per_event = {\n",
    "    \"boot\": deepcopy(vectors),\n",
    "    \"others\": deepcopy(vectors)\n",
    "}\n",
    "\n",
    "# Retrieve data\n",
    "max_total_names = 0\n",
    "n_total_resolvers   = 0\n",
    "max_total_resolvers = 0\n",
    "for device in d:\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for event, metrics in metrics_device.items():\n",
    "        # Skip multiple events\n",
    "        if event in fields_to_skip:\n",
    "            continue\n",
    "\n",
    "        event_category = \"boot\" if event == \"boot\" else \"others\"\n",
    "\n",
    "        vectors_event = vectors_per_event[event_category]\n",
    "\n",
    "        # Device-event pair\n",
    "        vectors_event[\"list_device_events\"].append(f\"{device}-{event}\")\n",
    "        \n",
    "        # First-level domain names\n",
    "        n_first_level_names = len(metrics.get(DictKeysMetrics.DOMAIN_NAMES_LVL_1.name, set()))\n",
    "        vectors_event[\"list_first_level_names\"].append(n_first_level_names)\n",
    "\n",
    "        # First-level domain resolvers\n",
    "        n_first_level_resolvers = len(metrics.get(DictKeysMetrics.DNS_SERVERS_LVL_1.name, set()))\n",
    "        vectors_event[\"list_first_level_resolvers\"].append(n_first_level_resolvers)\n",
    "\n",
    "        # Hidden domain names\n",
    "        n_hidden_names = len(metrics.get(DictKeysMetrics.DOMAIN_NAMES_HIDDEN.name, set()))\n",
    "        vectors_event[\"list_hidden_names\"].append(n_hidden_names)\n",
    "\n",
    "        # Hidden domain resolvers\n",
    "        n_hidden_resolvers = len(metrics.get(DictKeysMetrics.DNS_SERVERS_HIDDEN.name, set()))\n",
    "        vectors_event[\"list_hidden_resolvers\"].append(n_hidden_resolvers)\n",
    "\n",
    "        # Update aggregated values\n",
    "        max_total_names = max(max_total_names, n_first_level_names + n_hidden_names)\n",
    "        n_total_resolvers += n_first_level_resolvers + n_hidden_resolvers\n",
    "        max_total_resolvers = max(max_total_resolvers, n_first_level_resolvers + n_hidden_resolvers)\n",
    "\n",
    "list_first_level_names = vectors_per_event[\"boot\"][\"list_first_level_names\"] + vectors_per_event[\"others\"][\"list_first_level_names\"]\n",
    "list_first_level_resolvers = vectors_per_event[\"boot\"][\"list_first_level_resolvers\"] + vectors_per_event[\"others\"][\"list_first_level_resolvers\"]\n",
    "list_hidden_names = vectors_per_event[\"boot\"][\"list_hidden_names\"] + vectors_per_event[\"others\"][\"list_hidden_names\"]\n",
    "list_hidden_resolvers = vectors_per_event[\"boot\"][\"list_hidden_resolvers\"] + vectors_per_event[\"others\"][\"list_hidden_resolvers\"]\n",
    "\n",
    "#pprint(vectors_per_event)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "### Boot events only\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (FIG_WIDTH, 1)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.grid(axis='y')\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.3\n",
    "bar_positions = [bar_width/2 * pos for pos in [-1, 1]]\n",
    "bar_colors = [\"black\", \"gray\", \"white\", \"white\"]\n",
    "\n",
    "# Server names\n",
    "list_first_level_names_boot = vectors_per_event[\"boot\"][\"list_first_level_names\"]\n",
    "list_hidden_names_boot = vectors_per_event[\"boot\"][\"list_hidden_names\"]\n",
    "idx_servers = np.arange(len(list_first_level_names_boot))\n",
    "ax.bar(idx_servers + bar_positions[0], list_first_level_names_boot, width=bar_width, color=bar_colors[0], edgecolor='black', linewidth=LINE_THICKNESS, label=\"First-Level server names\")\n",
    "ax.bar(idx_servers + bar_positions[0], list_hidden_names_boot, width=bar_width, color=bar_colors[1], edgecolor='black', linewidth=LINE_THICKNESS, bottom=list_first_level_names_boot, label=\"Hidden server names\")\n",
    "\n",
    "# DNS resolvers\n",
    "list_first_level_resolvers_boot = vectors_per_event[\"boot\"][\"list_first_level_resolvers\"]\n",
    "list_hidden_resolvers_boot = vectors_per_event[\"boot\"][\"list_hidden_resolvers\"]\n",
    "idx_resolvers = np.arange(len(list_first_level_resolvers_boot))\n",
    "ax.bar(idx_resolvers + bar_positions[1], list_first_level_resolvers_boot, width=bar_width, color=bar_colors[2], edgecolor='black', linewidth=LINE_THICKNESS, label=\"First-Level DNS resolvers\")\n",
    "ax.bar(idx_resolvers + bar_positions[1], list_hidden_resolvers_boot, width=bar_width, color=bar_colors[3], edgecolor='black', hatch=\"////\", linewidth=LINE_THICKNESS, bottom=list_first_level_resolvers_boot, label=\"Hidden DNS resolvers\")\n",
    "\n",
    "## Plot metadata\n",
    "# x-axis\n",
    "ax.set_xticks(idx_servers)\n",
    "ax.set_xticklabels(idx_servers)\n",
    "labels_devices = [event.replace(\"-boot\", \"\") for event in vectors_per_event[\"boot\"][\"list_device_events\"]]\n",
    "#ax.set_xticklabels(labels_devices, rotation=45, ha=\"right\")  # Uncomment to set x-axis ticks to device names\n",
    "#ax.invert_yaxis()\n",
    "# y-axis\n",
    "ax.set_ylabel(\"Count\")\n",
    "max_y = max(max_total_names, max_total_resolvers)\n",
    "ax.set_yticks(range(0, max_y + 1, 2))\n",
    "\n",
    "# Show figure\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure to paper repository\n",
    "#save_to_paper(fig, \"count_dns_boot.pdf\")\n",
    "\n",
    "## Save legend as standalone figure\n",
    "figsize = (FIG_WIDTH, 0.4)\n",
    "fig_legend = plt.figure(figsize=figsize)\n",
    "legend = fig_legend.legend(*ax.get_legend_handles_labels(), loc=\"center\", ncol=2)\n",
    "fig_legend.canvas.draw()\n",
    "fig_legend.tight_layout()\n",
    "#save_to_paper(fig_legend, \"count_dns_boot_legend.pdf\")\n",
    "\n",
    "\n",
    "### All events\n",
    "\n",
    "# Bar metadata\n",
    "bar_width = 0.3\n",
    "bar_positions = [bar_width/2 * pos for pos in [-1, 1]]\n",
    "bar_colors = [\"black\", \"gray\", \"white\", \"white\"]\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (FIG_WIDTH, 6)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.grid(axis=\"x\")\n",
    "\n",
    "## Plot stacked bars\n",
    "x = 1 + np.arange(len(list_first_level_names))\n",
    "colors_default = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "# Domain names\n",
    "color = colors_default[0]\n",
    "ax.barh(x + bar_positions[0], list_first_level_names, height=bar_width, color=bar_colors[0], edgecolor=\"black\", linewidth=LINE_THICKNESS, label=\"First-Level domain names\")\n",
    "color = colors_default[3]\n",
    "ax.barh(x + bar_positions[0], list_hidden_names, height=bar_width, color=bar_colors[1], edgecolor=\"black\", linewidth=LINE_THICKNESS, left=list_first_level_names, label=\"Hidden domain names\")\n",
    "# DNS resolvers\n",
    "color = colors_default[1]\n",
    "ax.barh(x + bar_positions[1], list_first_level_resolvers, height=bar_width, color=bar_colors[2], edgecolor=\"black\", linewidth=LINE_THICKNESS, label=\"First-Level DNS resolvers\")\n",
    "color = colors_default[2]\n",
    "ax.barh(x + bar_positions[1], list_hidden_resolvers, height=bar_width, color=bar_colors[3], hatch=\"////\", edgecolor=\"black\", linewidth=LINE_THICKNESS, left=list_first_level_resolvers, label=\"Hidden DNS resolvers\")\n",
    "\n",
    "## Plot metadata\n",
    "# Event ID\n",
    "ax.set_ylabel(\"Event ID\")\n",
    "ax.set_ylim(0.5, len(list_first_level_names) + 0.5)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels([i if i == 1 or i % 5 == 0 else \"\" for i in range(1, len(list_first_level_names) + 1)])\n",
    "# Count\n",
    "ax.set_xlabel(\"Count\")\n",
    "max_count = max(max_total_names, max_total_resolvers)\n",
    "ax.set_xticks(range(0, max_count + 1, 1))\n",
    "ax.invert_yaxis()\n",
    "ax.legend(bbox_to_anchor=(0.41, 0.1))\n",
    "\n",
    "# Show figure\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure to paper repository\n",
    "#save_to_paper(fig, f\"count_dns_all.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Count pruned nodes per depth.\n",
    "Only for TP-Link HS110's toggle event.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def is_pruned(node: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given node is pruned.\n",
    "\n",
    "    Args:\n",
    "        node (dict): Node to check.\n",
    "    Returns:\n",
    "        bool: True if the node is pruned, False otherwise.\n",
    "    \"\"\"\n",
    "    return len(node.get(\"children\", [])) == 0\n",
    "\n",
    "\n",
    "def compute_pruned_nodes_per_depth(node: dict, data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively compute the count of pruned children nodes,\n",
    "    per parent node, per depth.\n",
    "\n",
    "    Args:\n",
    "        node (dict): Node to process.\n",
    "        data (dict): Accumulator to store the count of pruned children nodes.\n",
    "    Returns:\n",
    "        dict: Updated accumulator.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        depth = node.get(\"data\", [])[0]\n",
    "    except IndexError:\n",
    "        return data\n",
    "    else:\n",
    "        n_not_pruned, n_pruned = data.get(depth, (0, 0))\n",
    "        if is_pruned(node):\n",
    "            n_pruned += 1\n",
    "        else:\n",
    "            n_not_pruned += 1\n",
    "        data[depth] = (n_not_pruned, n_pruned)\n",
    "        for child in node.get(\"children\", []):\n",
    "            id = list(child.keys())[0]\n",
    "            compute_pruned_nodes_per_depth(child[id], data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "# Load event's JSON tree\n",
    "device = \"TpLinkPlug\"\n",
    "event  = \"toggle\"\n",
    "tree_json_path = Path(d[device][DictKeysMetrics.METRICS.name][event][DictKeysMetrics.FILE_TREE.name])\n",
    "dict_tree = None\n",
    "with open(tree_json_path, \"r\") as f:\n",
    "    dict_tree  = json.load(f)\n",
    "\n",
    "#print(json.dumps(data_tree, indent=2))\n",
    "\n",
    "# Read event signature tree\n",
    "data = {}\n",
    "for child in dict_tree[\"0_root\"][\"children\"]:\n",
    "    id = list(child.keys())[0]\n",
    "    compute_pruned_nodes_per_depth(child[id], data)\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (2, 3)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "# Get axis data\n",
    "x            = []\n",
    "y_not_pruned = []\n",
    "y_pruned     = []\n",
    "for depth, (n_not_pruned, n_pruned) in data.items():\n",
    "    x.append(depth)\n",
    "    y_not_pruned.append(n_not_pruned)\n",
    "    y_pruned.append(n_pruned)\n",
    "\n",
    "# Plot data\n",
    "ax.bar(x, y_not_pruned, label=\"Not pruned\", color=\"white\", edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "ax.bar(x, y_pruned, bottom=y_not_pruned, label=\"Pruned\", color=\"black\", edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "\n",
    "# Metadata\n",
    "ax.grid(axis=\"y\", linewidth=GRID_LINE_THICKNESS)\n",
    "ax.set_xlabel(\"Event signature tree depth\")\n",
    "ax.set_ylabel(\"Flow ID count\")\n",
    "ax.legend()\n",
    "ax.set_xticks(x)\n",
    "\n",
    "# Show ar save figure\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Count pruned nodes per depth,\n",
    "for all events.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "\n",
    "DEPTH_MAX = 4\n",
    "\n",
    "\n",
    "def is_pruned(node: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given node is pruned.\n",
    "\n",
    "    Args:\n",
    "        node (dict): Node to check.\n",
    "    Returns:\n",
    "        bool: True if the node is pruned, False otherwise.\n",
    "    \"\"\"\n",
    "    return len(node.get(\"children\", [])) == 0\n",
    "\n",
    "\n",
    "def compute_pruned_nodes_per_depth(node: dict, data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively compute the count of pruned nodes per tree depth.\n",
    "\n",
    "    Args:\n",
    "        node (dict): Node to process.\n",
    "        data (dict): Accumulator to store the count of pruned nodes.\n",
    "    Returns:\n",
    "        dict: Updated accumulator.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        depth = node.get(\"data\", [])[0]\n",
    "    except IndexError:\n",
    "        return data\n",
    "    else:\n",
    "        n_pruned = data.get(depth, 0)\n",
    "        if is_pruned(node):\n",
    "            n_pruned += 1\n",
    "        data[depth] = n_pruned\n",
    "        for child in node.get(\"children\", []):\n",
    "            id = list(child.keys())[0]\n",
    "            compute_pruned_nodes_per_depth(child[id], data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "dict_categories = {\n",
    "    \"boot\":   {\n",
    "        \"list_device_events\": []\n",
    "    },\n",
    "    \"others\": {\n",
    "        \"list_device_events\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load failed events data\n",
    "path_json_failed = Path(DEVICES_DIR, \"failed_events.json\")\n",
    "data_failed = {}\n",
    "with open(path_json_failed, \"r\") as f:\n",
    "    data_failed = json.load(f)\n",
    "\n",
    "\n",
    "# Compute count of pruned nodes per depth\n",
    "for device in d:\n",
    "    metrics_device = d[device][DictKeysMetrics.METRICS.name]\n",
    "    for event, metrics in metrics_device.items():\n",
    "        # Skip multiple events\n",
    "        if event in fields_to_skip:\n",
    "            continue\n",
    "\n",
    "        category = \"boot\" if event == \"boot\" else \"others\"\n",
    "        dict_category = dict_categories[category]\n",
    "        dict_category[\"list_device_events\"].append(f\"{device}-{event}\")\n",
    "\n",
    "        # Load event's JSON tree\n",
    "        tree_json_path = Path(d[device][DictKeysMetrics.METRICS.name][event][DictKeysMetrics.FILE_TREE.name])\n",
    "        dict_tree = None\n",
    "        with open(tree_json_path, \"r\") as f:\n",
    "            dict_tree  = json.load(f)\n",
    "        \n",
    "        # Compute count of pruned nodes\n",
    "        data = {}\n",
    "        for child in dict_tree[\"0_root\"][\"children\"]:\n",
    "            id = list(child.keys())[0]\n",
    "            compute_pruned_nodes_per_depth(child[id], data)\n",
    "        \n",
    "        # Get failed events iteration count for this event\n",
    "        failed_per_depth = data_failed.get(f\"{device}-{event}\", {})\n",
    "\n",
    "        for depth in range(1, DEPTH_MAX + 1):\n",
    "            data_depth = dict_category.get(depth, [])\n",
    "            n_pruned = data.get(depth, 0)\n",
    "            n_failed = failed_per_depth.get(str(depth), 0)\n",
    "            data_depth.append(n_pruned - n_failed)\n",
    "            dict_category[depth] = data_depth\n",
    "\n",
    "\n",
    "list_device_events = dict_categories[\"boot\"][\"list_device_events\"] + dict_categories[\"others\"][\"list_device_events\"]\n",
    "\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Initialize plot\n",
    "figsize = (FIG_WIDTH, 2.2)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "# Styles\n",
    "colors  = [\"white\", \"white\", \"gray\", \"black\"]\n",
    "hatches = [\"////\", \"\", \"\", \"\"]\n",
    "\n",
    "# Plot data\n",
    "x = range(1, len(list_device_events) + 1)\n",
    "bottom = np.zeros(len(list_device_events))\n",
    "max_x = 0\n",
    "for depth in range(1, DEPTH_MAX + 1):\n",
    "    list_n_pruned = dict_categories[\"boot\"][depth] + dict_categories[\"others\"][depth]\n",
    "    if depth == 1:\n",
    "        ax.bar(x, list_n_pruned, label=f\"depth={depth}\", color=colors[depth-1], hatch=hatches[depth-1], edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "    elif depth > 1:\n",
    "        ax.bar(x, list_n_pruned, bottom=bottom, label=f\"depth={depth}\", color=colors[depth-1], hatch=hatches[depth-1], edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "    \n",
    "    bottom += np.array(list_n_pruned)\n",
    "    max_x = max(max_x, max(bottom))\n",
    "\n",
    "# Metadata\n",
    "ax.grid(axis=\"y\", linewidth=GRID_LINE_THICKNESS)\n",
    "#ax.set_xlabel(\"Event ID\")\n",
    "ax.set_ylabel(\"Count of pruned Flow IDs\")\n",
    "ax.legend()\n",
    "ax.set_xlim(0, len(list_first_level_ids) + 1)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([i if i == 1 or i % 5 == 0 else \"\" for i in range(1, len(list_first_level_ids) + 1)])\n",
    "ax.set_ylim(1, max_x + 100)\n",
    "\n",
    "# Log scale y-axis\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.yaxis.get_major_formatter().set_useOffset(False)\n",
    "\n",
    "# Show ar save figure\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#save_to_paper(fig, \"count_pruned.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data from other works:\n",
    "- PingPong\n",
    "- BehavIoT\n",
    "- MUDgee\n",
    "- Blocking without Breaking\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Paths\n",
    "path_others = os.path.join(BASE_DIR, \"others\")\n",
    "\n",
    "\n",
    "def load_data_others(name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load device data retrieved from other works.\n",
    "\n",
    "    Args:\n",
    "        name (str): Name of the work.\n",
    "    Returns:\n",
    "        dict: Dictionary containing the device data.\n",
    "    \"\"\"\n",
    "    path_other = os.path.join(path_others, name)\n",
    "    list_json = glob.glob(os.path.join(path_other, \"*.json\"))\n",
    "    dict_other = {}\n",
    "    for json_file in list_json:\n",
    "        split  = os.path.basename(json_file).split(\".\")\n",
    "        device = split[0]\n",
    "        event  = split[1]\n",
    "        if event == \"no_boot\" or event == \"raw\":\n",
    "            continue\n",
    "\n",
    "        device_event = f\"{device}-{event}\"\n",
    "        dict_other[device_event] = {\n",
    "            \"policies\": {},\n",
    "            \"count\": 0\n",
    "        }\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data_json = json.load(f)\n",
    "            for policy in data_json[\"0_root\"][\"children\"]:\n",
    "                policy_name = list(policy.keys())[0]\n",
    "                dict_other[device_event][\"policies\"][policy_name] = policy[policy_name][\"data\"][1][0]\n",
    "                dict_other[device_event][\"count\"] += 1\n",
    "\n",
    "    return dict_other\n",
    "\n",
    "\n",
    "# Load data from PingPong\n",
    "dict_pingpong = load_data_others(\"pingpong\")\n",
    "pprint(dict_pingpong, indent=2)\n",
    "\n",
    "# Load data from BehavIoT\n",
    "dict_behaviot = load_data_others(\"behaviot\")\n",
    "pprint(dict_behaviot, indent=2)\n",
    "\n",
    "# Load data from MUDgee\n",
    "dict_mudgee = load_data_others(\"mudgee\")\n",
    "pprint(dict_mudgee, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare our work with PingPong and BehavIoT,\n",
    "at the event level.\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "set_device_events_pingpong = set(dict_pingpong.keys())\n",
    "set_device_events_behaviot = set(dict_behaviot.keys())\n",
    "\n",
    "# Initialize values\n",
    "values = {\n",
    "    \"ours\": {},\n",
    "    \"PingPong\": {},\n",
    "    \"BehavIoT\": {},\n",
    "}\n",
    "\n",
    "\n",
    "## Populate values\n",
    "\n",
    "# PingPong\n",
    "for device_event, data in dict_pingpong.items():\n",
    "    values[\"PingPong\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "# BehavIoT\n",
    "for device_event, data in dict_behaviot.items():\n",
    "    values[\"BehavIoT\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "\n",
    "## Ours\n",
    "\n",
    "list_device_events = [\n",
    "    \"TpLinkPlug-toggle\",\n",
    "    \"SmartThingsOutlet-boot\",\n",
    "    \"SmartThingsOutlet-toggle\",\n",
    "    \"DLinkCamera-stream\",\n",
    "    \"HueLight-toggle\"\n",
    "]\n",
    "for device_event in list_device_events:\n",
    "    device, event = device_event.split(\"-\")\n",
    "    device_event_metrics = d[device][DictKeysMetrics.METRICS.name][event]\n",
    "    values[\"ours\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: device_event_metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: device_event_metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "    }\n",
    "\n",
    "#pprint(values, indent=2)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Metadata\n",
    "# Bar width and positions\n",
    "bar_width = 0.2\n",
    "bar_positions = [bar_width/2 * pos for pos in [-2, 0, 2]]\n",
    "bar_colors = [\"black\", \"gray\", \"white\"]\n",
    "idx_devices = np.arange(len(list_device_events))\n",
    "# Figure size\n",
    "# Uncomment the following to set figure size\n",
    "figsize = (FIG_WIDTH, 2)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "# Uncomment the following to let matplotlib set the figure size automagically\n",
    "#fig, ax = plt.subplots()\n",
    "ax.grid(axis='x', linewidth=GRID_LINE_THICKNESS)\n",
    "\n",
    "# Plot bars\n",
    "max_value = 0\n",
    "for i, (work, data_device) in enumerate(values.items()):\n",
    "    values_work = list(reversed([values[work].get(device_event, {}).get(DictKeysMetrics.N_UNIQUE_NODES.name, 0) for device_event in list_device_events]))\n",
    "    label = \"This work\" if work == \"ours\" else work\n",
    "    ax.barh(idx_devices + bar_positions[i], values_work, bar_width, label=label, color=bar_colors[i], edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "    max_value = max(max_value, max(values_work))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Number of unique flow IDs')\n",
    "#ax.set_title('Number of unique flow IDs discovered by each work')\n",
    "ax.set_yticks(idx_devices)\n",
    "yticklabels = [device_event for device_event in reversed(list_device_events)]\n",
    "ax.set_yticklabels(yticklabels)\n",
    "ax.set_xticks(range(0, max_value + 1))\n",
    "ax.set_xticklabels([i if i % 2 == 0 else \"\" for i in range(0, max_value + 1)])\n",
    "ax.legend(reverse=True)\n",
    "\n",
    "# Show plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "#save_to_paper(fig, \"comparison_events.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare our work with MUDgee,\n",
    "at the device level.\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "devices_mudgee = set(dict_mudgee.keys())\n",
    "\n",
    "# Initialize values\n",
    "values = {\n",
    "    \"ours\": {},\n",
    "    \"MUDgee\": {}\n",
    "}\n",
    "\n",
    "\n",
    "## Populate values\n",
    "\n",
    "# MUDgee\n",
    "for device_event, data in dict_mudgee.items():\n",
    "    device = device_event.split(\"-\")[0]\n",
    "    values[\"MUDgee\"][device] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "# Our plugs\n",
    "for device in [\"TpLinkPlug\", \"SmartThingsOutlet\"]:\n",
    "    device_event_metrics = d[device][DictKeysMetrics.METRICS.name][\"device\"]\n",
    "    values[\"ours\"][device] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: device_event_metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: device_event_metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "    }\n",
    "\n",
    "# Our Hue Light\n",
    "pprint(d[\"HueLight\"][DictKeysMetrics.METRICS.name])\n",
    "device_event_metrics = d[\"HueLight\"][DictKeysMetrics.METRICS.name][\"device\"]\n",
    "values[\"ours\"][\"HueLight\"] = {\n",
    "    DictKeysMetrics.N_FIRST_LVL_NODES.name: device_event_metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name],\n",
    "    DictKeysMetrics.N_UNIQUE_NODES.name: device_event_metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "}\n",
    "\n",
    "pprint(values)\n",
    "\n",
    "\n",
    "## Plot\n",
    "\n",
    "# Metadata\n",
    "devices = list(values[\"ours\"].keys())\n",
    "# Bar width and positions\n",
    "bar_width = 0.2\n",
    "bar_positions = [bar_width/2 * pos for pos in [-1, 1]]\n",
    "colors_bars  = [\"black\", \"white\"]\n",
    "idx_devices = np.arange(len(devices))\n",
    "# Figure size\n",
    "# Uncomment the following to set figure size\n",
    "figsize = (FIG_WIDTH, 1.25)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "# Uncomment the following to let matplotlib set the figure size automagically\n",
    "#fig, ax = plt.subplots()\n",
    "ax.grid(axis='x')\n",
    "\n",
    "# Plot bars\n",
    "max_value = 0\n",
    "for i, (work, data_device) in enumerate(values.items()):\n",
    "    values_work = list(reversed([values[work].get(device, {}).get(DictKeysMetrics.N_UNIQUE_NODES.name, 0) for device in devices]))\n",
    "    label = \"This work\" if work == \"ours\" else work\n",
    "    ax.barh(idx_devices + bar_positions[i], values_work, bar_width, label=label, color=colors_bars[i], edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "    max_value = max(max_value, max(values_work))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Number of unique flow IDs')\n",
    "#ax.set_title('Number of unique flow IDs discovered by each work')\n",
    "ax.set_yticks(idx_devices)\n",
    "labels_devices = list(reversed(devices))\n",
    "ax.set_yticklabels(labels_devices)\n",
    "ax.set_xticks(range(0, max_value + 1, 2))\n",
    "ax.legend(reverse=True, bbox_to_anchor=(0.6, 0.5))\n",
    "\n",
    "# Show plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "#save_to_paper(fig, \"comparison_full.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare our work with both\n",
    "the event-level works (PingPong & BehavIoT)\n",
    "and the device-level work (MUDgee).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### DATA ###\n",
    "\n",
    "set_device_events_pingpong = set(dict_pingpong.keys())\n",
    "set_device_events_behaviot = set(dict_behaviot.keys())\n",
    "set_device_events_mudgee   = set(dict_mudgee.keys())\n",
    "\n",
    "# Initialize values\n",
    "values_events = {\n",
    "    \"ours\":     {},\n",
    "    \"PingPong\": {},\n",
    "    \"BehavIoT\": {}\n",
    "}\n",
    "values_devices = {\n",
    "    \"ours\":     {},\n",
    "    \"MUDgee\":   {}\n",
    "}\n",
    "\n",
    "\n",
    "## Populate values\n",
    "\n",
    "# PingPong\n",
    "for device_event, data in dict_pingpong.items():\n",
    "    values_events[\"PingPong\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "# BehavIoT\n",
    "for device_event, data in dict_behaviot.items():\n",
    "    values_events[\"BehavIoT\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "# MUDgee\n",
    "for device_event, data in dict_mudgee.items():\n",
    "    #device = device_event.split(\"-\")[0]\n",
    "    values_devices[\"MUDgee\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: data[\"count\"],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: data[\"count\"]\n",
    "    }\n",
    "\n",
    "\n",
    "## Ours\n",
    "\n",
    "list_events = [\n",
    "    \"TpLinkPlug-toggle\",\n",
    "    \"SmartThingsOutlet-boot\",\n",
    "    \"SmartThingsOutlet-toggle\",\n",
    "    \"DLinkCamera-stream\",\n",
    "    \"HueLight-toggle\"\n",
    "]\n",
    "for device_event in list_events:\n",
    "    device, event = device_event.split(\"-\")\n",
    "    device_event_metrics = d[device][DictKeysMetrics.METRICS.name][event]\n",
    "    values_events[\"ours\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: device_event_metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: device_event_metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "    }\n",
    "\n",
    "list_devices = [\n",
    "    \"TpLinkPlug-device\",\n",
    "    \"SmartThingsOutlet-device\",\n",
    "    \"HueLight-device\"\n",
    "]\n",
    "for device_event in list_devices:\n",
    "    device, event = device_event.split(\"-\")\n",
    "    device_event_metrics = d[device][DictKeysMetrics.METRICS.name][event]\n",
    "    values_devices[\"ours\"][device_event] = {\n",
    "        DictKeysMetrics.N_FIRST_LVL_NODES.name: device_event_metrics[DictKeysMetrics.N_FIRST_LVL_NODES.name],\n",
    "        DictKeysMetrics.N_UNIQUE_NODES.name: device_event_metrics[DictKeysMetrics.N_UNIQUE_NODES.name]\n",
    "    }\n",
    "\n",
    "pprint(values_events,  indent=2)\n",
    "pprint(values_devices, indent=2)\n",
    "\n",
    "\n",
    "### PLOT ###\n",
    "\n",
    "# Figure size\n",
    "# Uncomment the following to set figure size\n",
    "figsize = (FIG_WIDTH, 2)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "# Uncomment the following to let matplotlib set the figure size automagically\n",
    "#fig, ax = plt.subplots()\n",
    "ax.grid(axis='x', linewidth=GRID_LINE_THICKNESS)\n",
    "\n",
    "\n",
    "## Event-level\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.2\n",
    "bar_positions = [bar_width/2 * pos for pos in [-2, 0, 2]]\n",
    "bar_colors = [\"black\", \"gray\", \"white\"]\n",
    "idx_events = np.arange(len(list_events)) + len(list_devices)\n",
    "\n",
    "# Plot bars\n",
    "max_value = 0\n",
    "for i, (work, data_event) in enumerate(values_events.items()):\n",
    "    values_work = list(reversed([values_events[work].get(event, {}).get(DictKeysMetrics.N_UNIQUE_NODES.name, 0) for event in list_events]))\n",
    "    label = \"This work\" if work == \"ours\" else work\n",
    "    ax.barh(idx_events + bar_positions[i], values_work, bar_width, label=label, color=bar_colors[i], edgecolor=\"black\", linewidth=LINE_THICKNESS)\n",
    "    max_value = max(max_value, max(values_work))\n",
    "\n",
    "\n",
    "## Device-level\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.2\n",
    "bar_positions = [bar_width/2 * pos for pos in [-1, 1]]\n",
    "bar_colors  = [\"black\", \"white\"]\n",
    "bar_hatches = [\"\", \"////\"]\n",
    "idx_devices = np.arange(len(list_devices))\n",
    "\n",
    "# Plot bars\n",
    "for i, (work, data_devices) in enumerate(values_devices.items()):\n",
    "    values_work = list(reversed([values_devices[work].get(device, {}).get(DictKeysMetrics.N_UNIQUE_NODES.name, 0) for device in list_devices]))\n",
    "    label = None if work == \"ours\" else work\n",
    "    ax.barh(idx_devices + bar_positions[i], values_work, bar_width, label=label, color=bar_colors[i], edgecolor=\"black\", hatch=bar_hatches[i], linewidth=LINE_THICKNESS)\n",
    "    max_value = max(max_value, max(values_work))\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Number of unique Flow IDs')\n",
    "#ax.set_title('Number of unique Flow IDs discovered by each work')\n",
    "ax.set_yticks(np.concatenate((idx_devices, idx_events)))\n",
    "yticklabels = reversed(list_events + list_devices)\n",
    "ax.set_yticklabels(yticklabels)\n",
    "ax.set_xticks(range(0, max_value + 1))\n",
    "ax.set_xticklabels([i if i % 2 == 0 else \"\" for i in range(0, max_value + 1)])\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "#save_to_paper(fig, \"comparison_all.pdf\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
